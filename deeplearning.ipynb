{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e6e931",
   "metadata": {},
   "source": [
    "# より深いネットワークへ\n",
    "ここでは、これまでに学んだ技術を使って、ディープなネットワークを作り、MNISTデータセットの手書き文字の認識に挑む。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e9198",
   "metadata": {},
   "source": [
    "## よりディープなネットワークとは\n",
    "より深いCNNを、VGGと呼ぶ。ここでは、下図のような構成のネットワークを作成する。また、このネットワークの特徴としては、以下が挙げられる。\n",
    "\n",
    "- 3×3の小さなフィルターによる畳み込み層\n",
    "- 活性化関数はReLU\n",
    "- 全結合層の後にDropoutレイヤを使用\n",
    "- Adamによる最適化\n",
    "- 重みの初期値として「Heの初期値」を使用\n",
    "\n",
    "<img src='https://s3-ap-northeast-1.amazonaws.com/dragonarrow/uploads%2F1566104240795-VGG.png'>\n",
    "\n",
    "このネットワークを、学習済みのデータを利用して実行して実行したのが以下である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea81d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ネットワークの実装\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "\n",
    "class DeepConvNet:\n",
    "    \"\"\"認識率99%以上の高精度なConvNet\n",
    "\n",
    "    ネットワーク構成は下記の通り\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        affine - relu - dropout - affine - dropout - softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n",
    "                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 hidden_size=50, output_size=10):\n",
    "        # 重みの初期化===========\n",
    "        # 各層のニューロンひとつあたりが、前層のニューロンといくつのつながりがあるか（TODO:自動で計算する）\n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "        weight_init_scales = np.sqrt(2.0 / pre_node_nums)  # ReLUを使う場合に推奨される初期値\n",
    "        \n",
    "        self.params = {}\n",
    "        pre_channel_num = input_dim[0]\n",
    "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "            self.params['W' + str(idx+1)] = weight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
    "            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n",
    "            pre_channel_num = conv_param['filter_num']\n",
    "        self.params['W7'] = weight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "        self.params['b7'] = np.zeros(hidden_size)\n",
    "        self.params['W8'] = weight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b8'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成===========\n",
    "        self.layers = []\n",
    "        self.layers.append(Convolution(self.params['W1'], self.params['b1'], \n",
    "                           conv_param_1['stride'], conv_param_1['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W2'], self.params['b2'], \n",
    "                           conv_param_2['stride'], conv_param_2['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W3'], self.params['b3'], \n",
    "                           conv_param_3['stride'], conv_param_3['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W4'], self.params['b4'],\n",
    "                           conv_param_4['stride'], conv_param_4['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W5'], self.params['b5'],\n",
    "                           conv_param_5['stride'], conv_param_5['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W6'], self.params['b6'],\n",
    "                           conv_param_6['stride'], conv_param_6['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x, train_flg=False):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, train_flg)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x, train_flg=True)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx, train_flg=False)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        tmp_layers = self.layers.copy()\n",
    "        tmp_layers.reverse()\n",
    "        for layer in tmp_layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n",
    "            grads['b' + str(i+1)] = self.layers[layer_idx].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
    "            self.layers[layer_idx].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36eeb633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9935"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習済みデータの精度を算出\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "\n",
    "network.load_params(file_name=\"deep_convnet_params.pkl\")\n",
    "\n",
    "network.accuracy(x_test,t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9e6672",
   "metadata": {},
   "source": [
    "99.35%と、高い認識精度が出ていることがわかる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d4b80c",
   "metadata": {},
   "source": [
    "## さらに認識精度を高めるには\n",
    "「<a href=\"https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\">What is the class of this image?</a>」というWebサイトには、様々なデータセットを対象に、これまで論文などで発表された手法の認識精度がランキング形式で掲載されている。MNISTデータセットの識別に関しては、このサイトで上位を占めているほとんどの手法はCNNをベースとしたものである。また、このランキングの上位の手法を参考にすると、様々な認識精度を高めるためのテクニックを学ぶことができる。例としては、アンサンブル学習、学習係数の減衰、**Data Augmation**(データの拡張)などがある。特にData Augmationは、簡単で有効な手法である。Data Augmationでは、入力画像をアルゴリズムによって回転や移動などの微小な変化を与えることによって人工的にデータを拡張する。データの数が限られている場合には特に有効である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85535a6d",
   "metadata": {},
   "source": [
    "## 層を深くするということ\n",
    "層を深くすることの重要性については、理論的にそれほど多くのことは分かっていない。しかし、今までの研究の結果などからデータ的には多少の説明ができる。まず、ILSVRCなどに代表される大規模画像認識のコンペティションでは、最近の多くの上位の手法は、層を深くする傾向にある。これは、層を深くすることによって認識精度を向上させることができるからだと読み取れる。また、層を深くすることで、ネットワークのパラメータ数を少なくすることができる。小さなフィルターを重ねることで、受容野を広くすることができるという利点がある。（受容野とは、ニューロンに変化を生じさせる局所的な空間領域のこと。）また、層を深くすることで、学習データを少なくすることができ、学習効率が上がる。（より複雑な特徴をとらえることができるため。）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a2f84",
   "metadata": {},
   "source": [
    "# ディープラーニングの歴史\n",
    "近年のディープラーニングについて紹介する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53028020",
   "metadata": {},
   "source": [
    "## ImageNet\n",
    "ImageNetは100万を超える画像データのセット。この巨大なデータセットを用いて、ILSVRCという画像認識のコンペティションが毎年行われている。この中では、様々なテスト項目があるが、「クラス分類」についての結果を見ると、2012年からは常にディープラーニングがトップとなっている。特に、2015年の150層超から構成されるResNetにおいては、誤認識率を3.5％まで抑え、人間を超えたとまで言われている。\n",
    "そのようなディープラーニングの中でも、有名であるVGG、GoogLeNet、ResNetについて順に説明する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d1c39b",
   "metadata": {},
   "source": [
    "## VGG\n",
    "VGGは重みのある層を全部で16層または19層重ねて深くした、基本的なCNNである。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5825340",
   "metadata": {},
   "source": [
    "## GoogLeNet\n",
    "GoogLeNetは以下のような構成のネットワークであり、特徴としては、ネットワークが横方向にも広がりをもっていることが挙げられる。\n",
    "<img src='https://camo.qiitausercontent.com/ff9fdb708af0f67c865b0b1e41c4d0f42f0be738/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3230393730352f36376639383231332d613866662d646535322d326437652d3138613365663337636464322e706e67'>\n",
    "<br>\n",
    "横方向に幅を持つ構造をインセプション構造と言い、以下のような構成をしている。\n",
    "<img src='https://miro.medium.com/max/1400/1*DKjGRDd_lJeUfVlY50ojOA.png'>\n",
    "<br>\n",
    "これは、サイズの異なるフィルターとプーリングを複数適用し、その結果を結合するもの。また、このネットワークでは、1×1のフィルターの畳み込み演算を使用することで、チャンネル方向にサイズを減らし、パラメータの削減や処理の高速化を実現した。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66c9a3e",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "ResNetはMicrosoftのチームによって開発されたネットワーク。このネットワークでは、スキップ構造というものを用いて層を深くすることで性能が向上するようにできた。スキップ構造はとは、入力データを畳み込み層をまたいで出力に合算する構造。スキップ構造によって逆伝播時に信号が減衰することなく、効率のよい学習を行うことができる。ResNetでは2層ごとにスキップ構造を用いて入力と出力をつなぎ、層を深くしていく。実験によって、この方法で150層以上にしても認識精度は向上し続けることが分かった。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee283ac4",
   "metadata": {},
   "source": [
    "# ディープラーニングの高速化\n",
    "現在、多くのディープラーニングのフレームワークはGPUによる高速な演算に対応している。また、複数のGPUやコンピュータで処理を行う分散学習にも対応していることがある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a9a5b",
   "metadata": {},
   "source": [
    "## 高速化に関する問題\n",
    "AlexNetでは、多くの時間が畳み込み層の処理に費やされる。その処理時間は、CPUでは89%、GPUでは95%にまで達する。この数値は推論時のものであるが、学習時にも時間がかかるのは畳み込み層での処理である。よって、この処理時間をいかに短縮するかというのが課題となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4b8ff",
   "metadata": {},
   "source": [
    "## GPUによる高速化\n",
    "GPUはグラフィック専用ボードであるが、並列的な数値計算にも利用できる。そのような利用を、**GPUコンピューティング**という。現状、多くのディープラーニングのフレームワークが対応しているのは、NVIDIA社のGPUのみの場合が多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc66f2",
   "metadata": {},
   "source": [
    "## 分散学習\n",
    "複数のGPUやマシンで分散して計算を行い、学習することを分散学習という。TensorFlowやCNTKといったフレームワークは、分散学習を意識したものとなっている。分散学習においては、どのように計算を分散させるかということが問題とされている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a45ac3",
   "metadata": {},
   "source": [
    "## 演算精度のビット削減\n",
    "ディープラーニングの高速化においては、計算量に加えてハードウェア的条件がボトルネックとなりえる。このことから、ネットワークを流れるでデータのビット数はできるだけ小さくすることが望まれる。ディープラーニングにおいては、数値精度のビット数をそこまで必要としないということが研究で分かっている。これはニューラルネットワークのロバスト性によるものである。よって、ディープラーニングにでは16bitの半精度浮動小数点数（half float）を用いる。なお、Pythonでは一般的に64bitの浮動小数点数が使用される。また、最近では重みや中間データを1bitで表現する**Binarized Neural Networks**という手法が提案されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e20c3",
   "metadata": {},
   "source": [
    "# ディープラーニングの実用例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6495194",
   "metadata": {},
   "source": [
    "## 物体検出\n",
    "物体検出は、画像中から物体の位置の特定を含めてクラス分類を行う問題。この問題に対してCNNをベースとした手法がいくつか提案されている。その中でも、R-CNNと呼ばれるものの処理フローは以下のようなものである。\n",
    "<img src='https://takaolab.com/wp-content/uploads/2018/11/r-cnn.png'>\n",
    "<br>\n",
    "2.Extract region proposalsにおいて、オブジェクトらしい領域（候補領域）を何らかの形で抽出し、それをCNNネットワークにかけて分類を行っている。また、「Faster R-CNN」という手法では、候補領域の抽出もCNNで行う。全ての処理を一つのCNNで行うため、処理速度の向上が期待できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4e08d",
   "metadata": {},
   "source": [
    "## セグメンテーション\n",
    "セグメンテーションは、画像に対してピクセルレベルでクラス分類を行う問題。しかし、全てのピクセルに対して推論処理を実行すると時間がかかるため、FCN(Fully Convolutional Network)という手法が提案された。これは、一般のCNNが全結合層を含むのに対し、全結合層を同じ働きをする畳み込み層に置き換えるもの。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa98b3",
   "metadata": {},
   "source": [
    "## 画像キャプション作成\n",
    "画像を与えると、その画像を説明する文章を自動で生成するもの。この問題における手法には、代表的なものとしてNICがある。NICはCNNとRNN(Recurrent Neural Network)から構成される。RNNは、言語や時系列データなどの連続性のあるデータによく用いられる。なお、画像と自然言語といったような複数の種類の情報を組み合わせて処理することを**マルチモーダル処理**といい、近年注目を集めている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a2163c",
   "metadata": {},
   "source": [
    "# ディープラーニングの未来\n",
    "ディープラーニングの可能性を感じる研究をいくつか紹介する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462ce35",
   "metadata": {},
   "source": [
    "## 画像スタイル変換\n",
    "ディープラーニングを用いて、アーティストのような絵を描かせるという研究が近年進んでいる。例えば、コンテンツ画像とスタイル画像の2つの画像を入力し、後者の描画スタイルを前者の画像に適用したものを出力するというものがある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199603b0",
   "metadata": {},
   "source": [
    "## 画像生成\n",
    "何の画像も入力せず、新たな画像を描き出すというもの。これは、今までの教師あり学習と異なる、教師なし学習である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4befa7",
   "metadata": {},
   "source": [
    "## 自動運転\n",
    "人間の代わりにコンピュータが自動車を運転するというもの。様々な環境でもロバストに走行領域を正しく認識する方法として、CNNベースの手法が期待されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9537684d",
   "metadata": {},
   "source": [
    "## Deep Q-Network(強化学習)\n",
    "人が試行錯誤を経て学ぶように、コンピュータにも試行錯誤させて学習させる方法を強化学習と呼ぶ。強化学習では、エージェントというものが環境に応じて行動を取り、その行動によって環境が変化するということを繰り返している。このとき、環境の変化によってエージェントは何らかの報酬を得る。この報酬を最大にするのが強化学習の目的である。ディープラーニングを用いた強化学習の手法として、Deep Q-Network（通称DQN）というものがある。これはQ学習という強化学習のアルゴリズムをベースとしたもの。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
